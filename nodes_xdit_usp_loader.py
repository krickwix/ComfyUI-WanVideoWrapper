import torch
import os
import gc
from .utils import log
import numpy as np
from tqdm import tqdm

from .wanvideo.modules.model import WanModel
from .wanvideo.modules.t5 import T5EncoderModel
from .wanvideo.modules.clip import CLIPModel

from accelerate import init_empty_weights
from accelerate.utils import set_module_tensor_to_device
import accelerate

import folder_paths
import comfy.model_management as mm
from comfy.utils import load_torch_file, ProgressBar
import comfy.model_base
from comfy.sd import load_lora_for_models

script_directory = os.path.dirname(os.path.abspath(__file__))

device = mm.get_torch_device()
offload_device = mm.unet_offload_device()

try:
    from server import PromptServer
except:
    PromptServer = None

# Import Wan2.1 distributed components
try:
    import torch.distributed as dist
    from torch.distributed.fsdp import FullyShardedDataParallel as FSDP
    from torch.distributed.fsdp import MixedPrecision, ShardingStrategy
    from torch.distributed.fsdp.wrap import lambda_auto_wrap_policy
    from functools import partial
    FSDP_AVAILABLE = True
except ImportError:
    FSDP_AVAILABLE = False
    log.warning("FSDP not available. Please install PyTorch with distributed support.")

try:
    from xfuser.core.distributed import (
        init_distributed_environment,
        initialize_model_parallel,
        get_sequence_parallel_rank,
        get_sequence_parallel_world_size,
        get_sp_group,
    )
    from xfuser.core.long_ctx_attention import xFuserLongContextAttention
    XFUSER_AVAILABLE = True
except ImportError:
    XFUSER_AVAILABLE = False
    log.warning("xfuser not available. Please install xfuser for context parallel support.")

class WanDistributedConfig:
    """Configuration class for Wan2.1 distributed inference settings"""
    def __init__(self, 
                 world_size=1,
                 rank=0,
                 backend="nccl",
                 init_method="env://",
                 use_fsdp=False,
                 use_context_parallel=False,
                 ulysses_size=1,
                 ring_size=1,
                 t5_fsdp=False,
                 dit_fsdp=False,
                 use_usp=False,
                 t5_cpu=False,
                 param_dtype=torch.bfloat16,
                 reduce_dtype=torch.float32,
                 buffer_dtype=torch.float32,
                 sharding_strategy=ShardingStrategy.FULL_SHARD,
                 sync_module_states=True):
        self.world_size = world_size
        self.rank = rank
        self.backend = backend
        self.init_method = init_method
        self.use_fsdp = use_fsdp
        self.use_context_parallel = use_context_parallel
        self.ulysses_size = ulysses_size
        self.ring_size = ring_size
        self.t5_fsdp = t5_fsdp
        self.dit_fsdp = dit_fsdp
        self.use_usp = use_usp
        self.t5_cpu = t5_cpu
        self.param_dtype = param_dtype
        self.reduce_dtype = reduce_dtype
        self.buffer_dtype = buffer_dtype
        self.sharding_strategy = sharding_strategy
        self.sync_module_states = sync_module_states

# Import the regular WanVideoModel for compatibility
from .nodes_model_loading import WanVideoModel, WanVideoModelConfig

class WanDistributedModel(WanVideoModel):
    """WanVideo model wrapper for Wan2.1 distributed inference"""
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.distributed_config = None
        self.fsdp_model = None
        self.is_distributed = False



    def setup_distributed_inference(self, config: WanDistributedConfig):
        """Setup Wan2.1 distributed inference"""
        log.info("üåê Starting distributed inference setup...")
        
        if not FSDP_AVAILABLE:
            log.error("‚ùå FSDP not available!")
            raise ImportError("FSDP is required for distributed inference")
        log.info("‚úÖ FSDP is available")
        
        self.distributed_config = config
        self.is_distributed = False
        
        log.info(f"üìã Distributed config:")
        log.info(f"   - World size: {config.world_size}")
        log.info(f"   - Rank: {config.rank}")
        log.info(f"   - Backend: {config.backend}")
        log.info(f"   - Use FSDP: {config.use_fsdp}")
        log.info(f"   - Use context parallel: {config.use_context_parallel}")
        log.info(f"   - Ulysses size: {config.ulysses_size}")
        log.info(f"   - Ring size: {config.ring_size}")
        
        # Only initialize distributed environment if actually using multiple GPUs
        if config.world_size > 1:
            log.info("üöÄ Initializing multi-GPU distributed environment...")
            try:
                # For single-server multi-GPU, we'll use a simplified approach
                # Instead of full distributed processes, we'll use DataParallel-like sharding
                log.info("üîÑ Single-server multi-GPU mode detected")
                log.info("   - Using simplified multi-GPU approach (no process spawning)")
                
                # Set up device mapping for multi-GPU
                self.device_map = {}
                self.gpu_devices = list(range(config.world_size))
                log.info(f"   - GPU devices: {self.gpu_devices}")
                
                # Mark as distributed but with simplified setup
                self.is_distributed = True
                self.is_single_server = True
                log.info(f"‚úÖ Initialized single-server multi-GPU environment with {config.world_size} GPUs")
                
                # For single-server, context parallel requires process spawning which we're avoiding
                if config.use_context_parallel:
                    log.warning("‚ö†Ô∏è Context parallel disabled for single-server mode (requires process spawning)")
                    log.info("   - Use FSDP or device sharding instead for multi-GPU acceleration")
                    config.use_context_parallel = False
                else:
                    log.info("‚ÑπÔ∏è Context parallel not enabled")
            except Exception as e:
                log.error(f"‚ùå Failed to initialize distributed environment: {e}")
                log.info("üîÑ Falling back to single-GPU mode")
                config.world_size = 1
                config.rank = 0
                self.is_distributed = False
        else:
            log.info("‚ÑπÔ∏è Single-GPU mode, skipping distributed initialization")
        
        # Apply multi-GPU sharding if enabled (only for multi-GPU)
        if config.world_size > 1:
            log.info("üîß Applying multi-GPU sharding...")
            try:
                if config.use_fsdp and hasattr(self, 'is_single_server') and self.is_single_server:
                    # Use simplified FSDP for single-server
                    self.fsdp_model = self._apply_single_server_fsdp(config)
                    log.info("‚úÖ Applied single-server FSDP to model")
                elif config.use_fsdp:
                    # Use full FSDP for multi-server
                    self.fsdp_model = self._apply_fsdp(config)
                    log.info("‚úÖ Applied full FSDP to model")
                else:
                    # Use simple device sharding
                    self._apply_device_sharding(config)
                    log.info("‚úÖ Applied device sharding to model")
            except Exception as e:
                log.error(f"‚ùå Failed to apply multi-GPU sharding: {e}")
                log.info("üîÑ Falling back to single-GPU mode")
                config.world_size = 1
                config.rank = 0
                self.is_distributed = False
        else:
            log.info("‚ÑπÔ∏è Single-GPU mode, no sharding needed")
        
        log.info("=" * 60)
        log.info("üéØ DISTRIBUTED INFERENCE SETUP COMPLETE")
        log.info("=" * 60)
        log.info(f"üìä Final configuration:")
        log.info(f"   - FSDP: {config.use_fsdp}")
        log.info(f"   - Context Parallel: {config.use_context_parallel}")
        log.info(f"   - World Size: {config.world_size}")
        log.info(f"   - Is Distributed: {self.is_distributed}")
        log.info("=" * 60)

    def _apply_fsdp(self, config):
        """Apply FSDP to the model"""
        log.info("üîß Applying FSDP to model...")
        
        if not hasattr(self, 'diffusion_model') or self.diffusion_model is None:
            log.error("‚ùå Model must be loaded before applying FSDP")
            raise ValueError("Model must be loaded before applying FSDP")
        
        log.info(f"   - Param dtype: {config.param_dtype}")
        log.info(f"   - Reduce dtype: {config.reduce_dtype}")
        log.info(f"   - Buffer dtype: {config.buffer_dtype}")
        log.info(f"   - Sharding strategy: {config.sharding_strategy}")
        log.info(f"   - Sync module states: {config.sync_module_states}")
        log.info(f"   - Current device: {torch.cuda.current_device()}")
        
        # Define auto wrap policy for transformer blocks
        def auto_wrap_policy(module):
            return module in self.diffusion_model.blocks
        
        log.info("   - Auto wrap policy: wrap transformer blocks")
        
        try:
            # Apply FSDP
            fsdp_model = FSDP(
                module=self.diffusion_model,
                process_group=None,  # Use default process group
                sharding_strategy=config.sharding_strategy,
                auto_wrap_policy=partial(lambda_auto_wrap_policy, lambda_fn=auto_wrap_policy),
                mixed_precision=MixedPrecision(
                    param_dtype=config.param_dtype,
                    reduce_dtype=config.reduce_dtype,
                    buffer_dtype=config.buffer_dtype
                ),
                device_id=torch.cuda.current_device(),
                sync_module_states=config.sync_module_states
            )
            
            log.info("‚úÖ FSDP applied successfully")
            return fsdp_model
        except Exception as e:
            log.error(f"‚ùå Failed to apply FSDP: {e}")
            raise

    def _apply_single_server_fsdp(self, config):
        """Apply simplified FSDP for single-server multi-GPU"""
        log.info("üîß Applying single-server FSDP...")
        
        if not hasattr(self, 'diffusion_model') or self.diffusion_model is None:
            log.error("‚ùå Model must be loaded before applying FSDP")
            raise ValueError("Model must be loaded before applying FSDP")
        
        log.info(f"   - Using {len(self.gpu_devices)} GPUs: {self.gpu_devices}")
        log.info(f"   - Param dtype: {config.param_dtype}")
        log.info(f"   - Sharding strategy: {config.sharding_strategy}")
        
        try:
            # Create a simplified FSDP wrapper that works in single process
            # This will shard the model across GPUs without spawning processes
            fsdp_model = FSDP(
                module=self.diffusion_model,
                process_group=None,  # No process group for single-server
                sharding_strategy=config.sharding_strategy,
                auto_wrap_policy=None,  # No auto wrap for simplicity
                mixed_precision=MixedPrecision(
                    param_dtype=config.param_dtype,
                    reduce_dtype=config.reduce_dtype,
                    buffer_dtype=config.buffer_dtype
                ),
                device_id=torch.cuda.current_device(),
                sync_module_states=config.sync_module_states
            )
            
            log.info("‚úÖ Single-server FSDP applied successfully")
            return fsdp_model
        except Exception as e:
            log.error(f"‚ùå Failed to apply single-server FSDP: {e}")
            raise

    def _apply_device_sharding(self, config):
        """Apply simple device sharding across GPUs"""
        log.info("üîß Applying device sharding...")
        
        if not hasattr(self, 'diffusion_model') or self.diffusion_model is None:
            log.error("‚ùå Model must be loaded before applying device sharding")
            raise ValueError("Model must be loaded before applying device sharding")
        
        log.info(f"   - Sharding across {len(self.gpu_devices)} GPUs: {self.gpu_devices}")
        
        try:
            # Move different parts of the model to different GPUs
            # This is a simplified approach that doesn't require process spawning
            model = self.diffusion_model
            
            # Shard transformer blocks across GPUs
            if hasattr(model, 'blocks') and len(model.blocks) > 0:
                blocks_per_gpu = len(model.blocks) // len(self.gpu_devices)
                log.info(f"   - Sharding {len(model.blocks)} blocks across {len(self.gpu_devices)} GPUs")
                log.info(f"   - Blocks per GPU: {blocks_per_gpu}")
                
                for i, block in enumerate(model.blocks):
                    gpu_idx = i // blocks_per_gpu
                    if gpu_idx >= len(self.gpu_devices):
                        gpu_idx = len(self.gpu_devices) - 1
                    device = f"cuda:{self.gpu_devices[gpu_idx]}"
                    block.to(device)
                    log.info(f"   - Block {i} -> {device}")
            
            # Move other components to first GPU
            if hasattr(model, 'patch_embedding'):
                model.patch_embedding.to(f"cuda:{self.gpu_devices[0]}")
            if hasattr(model, 'pos_embedding'):
                model.pos_embedding.to(f"cuda:{self.gpu_devices[0]}")
            if hasattr(model, 'output_proj'):
                model.output_proj.to(f"cuda:{self.gpu_devices[0]}")
            
            log.info("‚úÖ Device sharding applied successfully")
            
        except Exception as e:
            log.error(f"‚ùå Failed to apply device sharding: {e}")
            raise

    def forward_distributed(self, *args, **kwargs):
        """Forward pass using distributed inference"""
        # Ensure inputs are in the correct dtype
        if hasattr(self, 'base_dtype'):
            args = [arg.to(dtype=self.base_dtype) if torch.is_tensor(arg) else arg for arg in args]
            kwargs = {k: v.to(dtype=self.base_dtype) if torch.is_tensor(v) else v for k, v in kwargs.items()}
        
        if self.fsdp_model is not None:
            return self.fsdp_model(*args, **kwargs)
        elif hasattr(self, 'diffusion_model'):
            return self.diffusion_model(*args, **kwargs)
        else:
            raise ValueError("No model available for inference")

    def cleanup(self):
        """Cleanup distributed resources"""
        log.info("üßπ Cleaning up distributed resources...")
        
        if self.fsdp_model is not None:
            log.info("   - Cleaning up FSDP model...")
            try:
                # Free FSDP storage
                for m in self.fsdp_model.modules():
                    if isinstance(m, FSDP):
                        from torch.distributed.utils import _free_storage
                        _free_storage(m._handle.flat_param.data)
                del self.fsdp_model
                self.fsdp_model = None
                log.info("   - FSDP model cleaned up")
            except Exception as e:
                log.warning(f"   - FSDP cleanup warning: {e}")
        
        if self.is_distributed and hasattr(self, 'is_single_server') and self.is_single_server:
            log.info("   - Single-server mode, no process group to destroy")
            self.is_distributed = False
        elif self.is_distributed and dist.is_initialized():
            log.info("   - Destroying process group...")
            try:
                dist.destroy_process_group()
                self.is_distributed = False
                log.info("   - Process group destroyed")
            except Exception as e:
                log.warning(f"   - Process group cleanup warning: {e}")
        
        log.info("   - Running garbage collection...")
        gc.collect()
        torch.cuda.empty_cache()
        log.info("‚úÖ Cleanup complete")

class WanDistributedConfigNode:
    """ComfyUI node for configuring Wan2.1 distributed settings"""
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "world_size": ("INT", {"default": 1, "min": 1, "max": 8, "step": 1, "tooltip": "Number of processes/GPUs (1 for single GPU)"}),
                "rank": ("INT", {"default": 0, "min": 0, "max": 7, "step": 1, "tooltip": "Process rank (0 to world_size-1)"}),
                "backend": (["nccl", "gloo"], {"default": "nccl", "tooltip": "Distributed backend"}),
                "use_fsdp": ("BOOLEAN", {"default": False, "tooltip": "Use FSDP for model sharding (requires world_size > 1)"}),
                "use_context_parallel": ("BOOLEAN", {"default": False, "tooltip": "Use context parallel (requires xfuser)"}),
                "ulysses_size": ("INT", {"default": 1, "min": 1, "max": 4, "step": 1, "tooltip": "Ulysses size for context parallel"}),
                "ring_size": ("INT", {"default": 1, "min": 1, "max": 4, "step": 1, "tooltip": "Ring size for context parallel"}),
                "t5_fsdp": ("BOOLEAN", {"default": False, "tooltip": "Use FSDP for T5 text encoder"}),
                "dit_fsdp": ("BOOLEAN", {"default": False, "tooltip": "Use FSDP for DIT model"}),
                "use_usp": ("BOOLEAN", {"default": False, "tooltip": "Use USP (Ultra-Scalable Parallelism)"}),
                "t5_cpu": ("BOOLEAN", {"default": False, "tooltip": "Load T5 on CPU"}),
            },
            "optional": {
                "param_dtype": (["bfloat16", "float16", "float32"], {"default": "bfloat16", "tooltip": "Parameter dtype for FSDP"}),
                "reduce_dtype": (["float32", "bfloat16", "float16"], {"default": "float32", "tooltip": "Reduce dtype for FSDP"}),
                "buffer_dtype": (["float32", "bfloat16", "float16"], {"default": "float32", "tooltip": "Buffer dtype for FSDP"}),
                "sharding_strategy": (["FULL_SHARD", "SHARD_GRAD_OP", "NO_SHARD"], {"default": "FULL_SHARD", "tooltip": "FSDP sharding strategy"}),
                "sync_module_states": ("BOOLEAN", {"default": True, "tooltip": "Sync module states in FSDP"}),
            }
        }

    RETURN_TYPES = ("WANDISTRIBUTEDCONFIG",)
    RETURN_NAMES = ("wan_distributed_config",)
    FUNCTION = "create_config"
    CATEGORY = "WanVideoWrapper/Distributed"
    DESCRIPTION = "Configure Wan2.1 distributed inference settings"

    def create_config(self, **kwargs):
        # Convert string dtypes to torch dtypes
        dtype_map = {
            "bfloat16": torch.bfloat16,
            "float16": torch.float16,
            "float32": torch.float32
        }
        
        if "param_dtype" in kwargs:
            kwargs["param_dtype"] = dtype_map[kwargs["param_dtype"]]
        if "reduce_dtype" in kwargs:
            kwargs["reduce_dtype"] = dtype_map[kwargs["reduce_dtype"]]
        if "buffer_dtype" in kwargs:
            kwargs["buffer_dtype"] = dtype_map[kwargs["buffer_dtype"]]
        
        # Convert sharding strategy string to enum
        if "sharding_strategy" in kwargs:
            strategy_map = {
                "FULL_SHARD": ShardingStrategy.FULL_SHARD,
                "SHARD_GRAD_OP": ShardingStrategy.SHARD_GRAD_OP,
                "NO_SHARD": ShardingStrategy.NO_SHARD
            }
            kwargs["sharding_strategy"] = strategy_map[kwargs["sharding_strategy"]]
        
        config = WanDistributedConfig(**kwargs)
        return (config,)

class WanDistributedModelLoader:
    """ComfyUI node for loading WanVideo models with Wan2.1 distributed inference"""
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "model": (folder_paths.get_filename_list("diffusion_models"), {"tooltip": "WanVideo model to load"}),
                "base_precision": (["fp32", "bf16", "fp16"], {"default": "bf16"}),
                "wan_distributed_config": ("WANDISTRIBUTEDCONFIG", {"tooltip": "Wan2.1 distributed configuration"}),
            },
            "optional": {
                "attention_mode": ([
                    "sdpa",
                    "flash_attn_2", 
                    "flash_attn_3",
                    "sageattn",
                    "flex_attention",
                    "radial_sage_attention",
                ], {"default": "sdpa"}),
                "lora": ("WANVIDLORA", {"default": None}),
                "vace_model": ("VACEPATH", {"default": None}),
            }
        }

    RETURN_TYPES = ("WANVIDEOMODEL",)
    RETURN_NAMES = ("model",)
    FUNCTION = "loadmodel"
    CATEGORY = "WanVideoWrapper/Distributed"
    DESCRIPTION = "Load WanVideo model with Wan2.1 distributed inference support"

    def loadmodel(self, model, base_precision, wan_distributed_config, attention_mode="sdpa", lora=None, vace_model=None):
        log.info("=" * 80)
        log.info("üöÄ STARTING WAN2.1 DISTRIBUTED MODEL LOADER")
        log.info("=" * 80)
        log.info(f"üìã Input parameters:")
        log.info(f"   - Model: {model}")
        log.info(f"   - Base precision: {base_precision}")
        log.info(f"   - Attention mode: {attention_mode}")
        log.info(f"   - World size: {wan_distributed_config.world_size}")
        log.info(f"   - Use FSDP: {wan_distributed_config.use_fsdp}")
        log.info(f"   - Use context parallel: {wan_distributed_config.use_context_parallel}")
        log.info(f"   - LoRA: {lora is not None}")
        log.info(f"   - VACE model: {vace_model is not None}")
        
        # Check FSDP availability
        log.info("üîç Checking FSDP availability...")
        if not FSDP_AVAILABLE:
            log.error("‚ùå FSDP not available!")
            raise ImportError("FSDP is required for distributed inference. Please install PyTorch with distributed support.")
        log.info("‚úÖ FSDP is available")
        
        # Check GPU availability
        log.info("üîç Checking GPU availability...")
        available_gpus = torch.cuda.device_count()
        log.info(f"   - Available GPUs: {available_gpus}")
        log.info(f"   - Requested GPUs: {wan_distributed_config.world_size}")
        
        if available_gpus < wan_distributed_config.world_size:
            log.error(f"‚ùå Not enough GPUs! Requested {wan_distributed_config.world_size} but only {available_gpus} available")
            raise ValueError(f"Requested {wan_distributed_config.world_size} GPUs but only {available_gpus} are available")
        log.info("‚úÖ GPU count is sufficient")
        
        log.info(f"üéØ Loading WanVideo model with Wan2.1 distributed inference on {wan_distributed_config.world_size} GPUs")
        
        # Unload existing models
        log.info("üßπ Unloading existing models...")
        mm.unload_all_models()
        mm.cleanup_models()
        mm.soft_empty_cache()
        log.info("‚úÖ Models unloaded and cache cleared")
        
        # Set up device and dtype
        log.info("‚öôÔ∏è Setting up devices and data types...")
        device = mm.get_torch_device()
        offload_device = mm.unet_offload_device()
        base_dtype = {"bf16": torch.bfloat16, "fp16": torch.float16, "fp32": torch.float32}[base_precision]
        log.info(f"   - Main device: {device}")
        log.info(f"   - Offload device: {offload_device}")
        log.info(f"   - Base dtype: {base_dtype}")
        log.info("‚úÖ Device setup complete")
        
        # Load model state dict
        log.info("üìÅ Loading model state dict...")
        model_path = folder_paths.get_full_path_or_raise("diffusion_models", model)
        log.info(f"   - Model path: {model_path}")
        log.info(f"   - Loading to device: {offload_device}")
        
        try:
            sd = load_torch_file(model_path, device=offload_device, safe_load=True)
            log.info(f"‚úÖ Model loaded successfully. State dict keys: {len(sd)}")
        except Exception as e:
            log.error(f"‚ùå Failed to load model: {e}")
            raise
        
        # Handle VACE model if provided
        if vace_model is not None:
            log.info("üîß Loading VACE model...")
            try:
                vace_sd = load_torch_file(vace_model["path"], device=offload_device, safe_load=True)
                sd.update(vace_sd)
                log.info(f"‚úÖ VACE model loaded. Total keys: {len(sd)}")
            except Exception as e:
                log.error(f"‚ùå Failed to load VACE model: {e}")
                raise
        else:
            log.info("‚ÑπÔ∏è No VACE model provided")
        
        # Standardize state dict keys
        log.info("üîß Standardizing state dict keys...")
        first_key = next(iter(sd))
        log.info(f"   - First key: {first_key}")
        
        if first_key.startswith("model.diffusion_model."):
            log.info("   - Detected 'model.diffusion_model.' prefix, removing...")
            new_sd = {}
            for key, value in sd.items():
                new_key = key.replace("model.diffusion_model.", "", 1)
                new_sd[new_key] = value
            sd = new_sd
            log.info("‚úÖ Removed 'model.diffusion_model.' prefix")
        elif first_key.startswith("model."):
            log.info("   - Detected 'model.' prefix, removing...")
            new_sd = {}
            for key, value in sd.items():
                new_key = key.replace("model.", "", 1)
                new_sd[new_key] = value
            sd = new_sd
            log.info("‚úÖ Removed 'model.' prefix")
        else:
            log.info("   - No prefix detected, keys are already standardized")
        
        log.info(f"   - Final key count: {len(sd)}")
        
        # Validate model
        log.info("üîç Validating model structure...")
        if not "patch_embedding.weight" in sd:
            log.error("‚ùå Invalid WanVideo model: missing 'patch_embedding.weight'")
            raise ValueError("Invalid WanVideo model selected")
        log.info("‚úÖ Model validation passed")
        
        # Extract model configuration
        log.info("üìê Extracting model configuration...")
        try:
            dim = sd["patch_embedding.weight"].shape[0]
            in_features = sd["blocks.0.self_attn.k.weight"].shape[1]
            out_features = sd["blocks.0.self_attn.k.weight"].shape[0]
            in_channels = sd["patch_embedding.weight"].shape[1]
            ffn_dim = sd["blocks.0.ffn.0.bias"].shape[0]
            ffn2_dim = sd["blocks.0.ffn.2.weight"].shape[1]
            
            log.info(f"   - Dimension: {dim}")
            log.info(f"   - In features: {in_features}")
            log.info(f"   - Out features: {out_features}")
            log.info(f"   - In channels: {in_channels}")
            log.info(f"   - FFN dim: {ffn_dim}")
            log.info(f"   - FFN2 dim: {ffn2_dim}")
            log.info("‚úÖ Model configuration extracted")
        except Exception as e:
            log.error(f"‚ùå Failed to extract model configuration: {e}")
            raise
        
        # Determine model type
        log.info("üè∑Ô∏è Determining model type...")
        if not "text_embedding.0.weight" in sd:
            model_type = "no_cross_attn"
            log.info("   - Model type: no_cross_attn (no text embedding)")
        elif "model_type.Wan2_1-FLF2V-14B-720P" in sd or "img_emb.emb_pos" in sd or "flf2v" in model.lower():
            model_type = "fl2v"
            log.info("   - Model type: fl2v (FLF2V model)")
        elif in_channels in [36, 48]:
            model_type = "i2v"
            log.info(f"   - Model type: i2v (in_channels: {in_channels})")
        elif in_channels == 16:
            model_type = "t2v"
            log.info("   - Model type: t2v (in_channels: 16)")
        elif "control_adapter.conv.weight" in sd:
            model_type = "t2v"
            log.info("   - Model type: t2v (with control adapter)")
        else:
            model_type = "unknown"
            log.warning(f"   - Model type: unknown (in_channels: {in_channels})")
        
        num_heads = 40 if dim == 5120 else 12
        num_layers = 40 if dim == 5120 else 30
        log.info(f"   - Num heads: {num_heads}")
        log.info(f"   - Num layers: {num_layers}")
        log.info(f"‚úÖ Model type determined: {model_type}")
        
        # Handle VACE layers
        log.info("üîß Handling VACE layers...")
        vace_layers, vace_in_dim = None, None
        if "vace_blocks.0.after_proj.weight" in sd:
            log.info("   - VACE blocks detected in model")
            if in_channels != 16:
                log.error("‚ùå VACE only works properly with T2V models")
                raise ValueError("VACE only works properly with T2V models.")
            model_type = "t2v"
            if dim == 5120:
                vace_layers = [0, 5, 10, 15, 20, 25, 30, 35]
                log.info("   - Using 14B VACE layers: [0, 5, 10, 15, 20, 25, 30, 35]")
            else:
                vace_layers = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28]
                log.info("   - Using 1.3B VACE layers: [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28]")
            vace_in_dim = 96
            log.info(f"   - VACE input dimension: {vace_in_dim}")
            log.info("‚úÖ VACE layers configured")
        else:
            log.info("‚ÑπÔ∏è No VACE blocks detected")
        
        log.info(f"üìä Final model configuration:")
        log.info(f"   - Model type: {model_type}")
        log.info(f"   - Num heads: {num_heads}")
        log.info(f"   - Num layers: {num_layers}")
        log.info(f"   - VACE layers: {vace_layers}")
        log.info(f"   - VACE in dim: {vace_in_dim}")
        
        # Create transformer configuration
        log.info("‚öôÔ∏è Creating transformer configuration...")
        transformer_config = {
            "dim": dim,
            "in_features": in_features,
            "out_features": out_features,
            "ffn_dim": ffn_dim,
            "ffn2_dim": ffn2_dim,
            "eps": 1e-06,
            "freq_dim": 256,
            "in_dim": in_channels,
            "model_type": model_type,
            "out_dim": 16,
            "text_len": 512,
            "num_heads": num_heads,
            "num_layers": num_layers,
            "attention_mode": attention_mode,
            "rope_func": "comfy",
            "main_device": device,
            "offload_device": offload_device,
            "vace_layers": vace_layers,
            "vace_in_dim": vace_in_dim,
            "inject_sample_info": True if "fps_embedding.weight" in sd else False,
            "add_ref_conv": True if "ref_conv.weight" in sd else False,
            "in_dim_ref_conv": sd["ref_conv.weight"].shape[1] if "ref_conv.weight" in sd else None,
            "add_control_adapter": True if "control_adapter.conv.weight" in sd else False,
        }
        
        log.info(f"   - Attention mode: {attention_mode}")
        log.info(f"   - Inject sample info: {transformer_config['inject_sample_info']}")
        log.info(f"   - Add ref conv: {transformer_config['add_ref_conv']}")
        log.info(f"   - Add control adapter: {transformer_config['add_control_adapter']}")
        log.info("‚úÖ Transformer configuration created")
        
        # Create WanVideo model
        log.info("üèóÔ∏è Creating WanVideo model with empty weights...")
        try:
            with init_empty_weights():
                transformer = WanModel(**transformer_config)
            transformer.eval()
            log.info("‚úÖ WanVideo model created successfully")
        except Exception as e:
            log.error(f"‚ùå Failed to create WanVideo model: {e}")
            raise
        
        # Create ComfyUI model wrapper
        log.info("üé≠ Creating ComfyUI model wrapper...")
        try:
            comfy_model = WanDistributedModel(
                WanVideoModelConfig(base_dtype),
                model_type=comfy.model_base.ModelType.FLOW,
                device=device,
            )
            
            comfy_model.diffusion_model = transformer
            comfy_model.load_device = offload_device
            
            # Ensure the model maintains consistent dtype
            comfy_model.base_dtype = base_dtype
            log.info(f"   - Model base dtype: {base_dtype}")
            log.info("‚úÖ ComfyUI model wrapper created")
        except Exception as e:
            log.error(f"‚ùå Failed to create ComfyUI model wrapper: {e}")
            raise
        
        # Load model weights
        log.info("‚öñÔ∏è Loading model weights...")
        try:
            param_count = sum(1 for _ in transformer.named_parameters())
            log.info(f"   - Total parameters to load: {param_count}")
            log.info(f"   - Target dtype: {base_dtype}")
            pbar = ProgressBar(param_count)
            
            loaded_count = 0
            for name, param in tqdm(transformer.named_parameters(), 
                    desc=f"Loading transformer parameters", 
                    total=param_count,
                    leave=True):
                try:
                    # Ensure the loaded weight has the correct dtype
                    weight_value = sd[name].to(dtype=base_dtype)
                    set_module_tensor_to_device(transformer, name, device=offload_device, dtype=base_dtype, value=weight_value)
                    loaded_count += 1
                    if loaded_count % 100 == 0:
                        log.info(f"   - Loaded {loaded_count}/{param_count} parameters")
                except Exception as e:
                    log.error(f"‚ùå Failed to load parameter {name}: {e}")
                    raise
                pbar.update(1)
            
            log.info(f"‚úÖ Successfully loaded {loaded_count} parameters")
            
            # Ensure the model is in the correct dtype
            log.info("üîß Converting model to target dtype...")
            transformer = transformer.to(dtype=base_dtype)
            log.info(f"‚úÖ Model converted to {base_dtype}")
            
        except Exception as e:
            log.error(f"‚ùå Failed to load model weights: {e}")
            raise
        
        # Setup distributed inference
        log.info("üåê Setting up distributed inference...")
        try:
            comfy_model.setup_distributed_inference(wan_distributed_config)
            log.info("‚úÖ Distributed inference setup complete")
        except Exception as e:
            log.error(f"‚ùå Failed to setup distributed inference: {e}")
            raise
        
        # Handle LoRA if provided
        if lora is not None:
            log.warning("‚ö†Ô∏è LoRA support in distributed inference is experimental")
            # TODO: Implement LoRA support for distributed inference
        else:
            log.info("‚ÑπÔ∏è No LoRA provided")
        
        # Create model patcher
        log.info("üîß Creating model patcher...")
        try:
            patcher = comfy.model_patcher.ModelPatcher(comfy_model, device, offload_device)
            patcher.model.is_patched = True
            log.info("‚úÖ Model patcher created")
        except Exception as e:
            log.error(f"‚ùå Failed to create model patcher: {e}")
            raise
        
        # Set model metadata
        log.info("üìù Setting model metadata...")
        try:
            patcher.model["dtype"] = base_dtype
            patcher.model["base_path"] = model_path
            patcher.model["model_name"] = model
            patcher.model["manual_offloading"] = True
            patcher.model["quantization"] = "disabled"
            patcher.model["auto_cpu_offload"] = False
            patcher.model["control_lora"] = False
            patcher.model["distributed_inference"] = True
            patcher.model["distributed_config"] = wan_distributed_config
            log.info("‚úÖ Model metadata set")
        except Exception as e:
            log.error(f"‚ùå Failed to set model metadata: {e}")
            raise
        
        # Clean up
        log.info("üßπ Cleaning up...")
        try:
            del sd
            gc.collect()
            mm.soft_empty_cache()
            log.info("‚úÖ Cleanup complete")
        except Exception as e:
            log.warning(f"‚ö†Ô∏è Cleanup warning: {e}")
        
        log.info("=" * 80)
        log.info("üéâ SUCCESSFULLY LOADED WANVIDEO MODEL WITH WAN2.1 DISTRIBUTED INFERENCE")
        log.info("=" * 80)
        log.info(f"üìä Summary:")
        log.info(f"   - Model: {model}")
        log.info(f"   - Type: {model_type}")
        log.info(f"   - GPUs: {wan_distributed_config.world_size}")
        log.info(f"   - FSDP: {wan_distributed_config.use_fsdp}")
        log.info(f"   - Context Parallel: {wan_distributed_config.use_context_parallel}")
        log.info(f"   - Parameters loaded: {loaded_count}")
        log.info("=" * 80)
        
        return (patcher,)

# Register the new nodes
NODE_CLASS_MAPPINGS = {
    "WanDistributedConfig": WanDistributedConfigNode,
    "WanDistributedModelLoader": WanDistributedModelLoader,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "WanDistributedConfig": "Wan2.1 Distributed Config",
    "WanDistributedModelLoader": "Wan2.1 Distributed Model Loader",
} 